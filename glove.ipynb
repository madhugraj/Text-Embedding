{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import flair\n",
    "from flair.data import Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "import pandas as pd\n",
    "data = pd.read_csv('train_E6oV3lV.csv') \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run', \"@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\", '  bihday your majesty', '#model   i love u take with u all the time in urð\\x9f\\x93±!!! ð\\x9f\\x98\\x99ð\\x9f\\x98\\x8eð\\x9f\\x91\\x84ð\\x9f\\x91\\x85ð\\x9f\\x92¦ð\\x9f\\x92¦ð\\x9f\\x92¦  ', ' factsguide: society now    #motivation']\n"
     ]
    }
   ],
   "source": [
    "text = data['tweet']\n",
    "txt = text.tolist()\n",
    "print(txt[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings\n",
    "from flair.embeddings import CharacterEmbeddings\n",
    "from flair.embeddings import StackedEmbeddings\n",
    "from flair.embeddings import FlairEmbeddings\n",
    "from flair.embeddings import BertEmbeddings\n",
    "from flair.embeddings import ELMoEmbeddings\n",
    "\n",
    "\n",
    "### Initialising embeddings (un-comment to use others) ###\n",
    "\n",
    "glove_embedding = WordEmbeddings('glove')\n",
    "character_embeddings = CharacterEmbeddings()\n",
    "flair_forward  = FlairEmbeddings('news-forward-fast')\n",
    "flair_backward = FlairEmbeddings('news-backward-fast')\n",
    "bert_embedding = BertEmbeddings()\n",
    "\n",
    "\n",
    "stacked_embeddings = StackedEmbeddings( embeddings = [ glove_embedding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5706,  0.4418,  0.7010, -0.4171, -0.3406,  0.0234, -0.0715,  0.4818,\n",
      "        -0.0131,  0.1683, -0.1339,  0.0406,  0.1583, -0.4434, -0.0194, -0.0097,\n",
      "        -0.0463,  0.0932, -0.2733,  0.2285,  0.3309, -0.3647,  0.0787,  0.3585,\n",
      "         0.4476, -0.2299,  0.1808, -0.6265,  0.0539, -0.2915, -0.4256,  0.6290,\n",
      "         0.1439, -0.0460, -0.2101,  0.4888, -0.0577,  0.3743, -0.0301, -0.3449,\n",
      "        -0.2970,  0.1509,  0.2825, -0.1658,  0.0761, -0.0930,  0.7936, -0.6049,\n",
      "        -0.1887, -1.0173,  0.3196, -0.1634,  0.5418,  1.1725, -0.4787, -3.3842,\n",
      "        -0.0813, -0.3528,  1.8372,  0.4452, -0.5267,  0.9979, -0.3218,  0.0335,\n",
      "         1.1783, -0.0729,  0.3974,  0.2617,  0.3311, -0.3563, -0.1656, -0.4438,\n",
      "        -0.1418, -0.3798,  0.2899, -0.0291, -0.3517, -0.2769, -1.3440,  0.1955,\n",
      "         0.1689,  0.0402, -0.8021,  0.2337, -1.3837, -0.0231,  0.0854, -0.7405,\n",
      "        -0.0739, -0.5884, -0.0857, -0.1053, -0.5157,  0.1504, -0.1669, -0.1637,\n",
      "        -0.2270, -0.6610,  0.4720,  0.3725])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([-0.5426,  0.4148,  1.0322, -0.4024,  0.4669,  0.2182, -0.0749,  0.4733,\n",
      "         0.0810, -0.2208, -0.1281, -0.1144,  0.5089,  0.1157,  0.0282, -0.3628,\n",
      "         0.4382,  0.0475,  0.2028,  0.4986, -0.1007,  0.1327,  0.1697,  0.1165,\n",
      "         0.3135,  0.2571,  0.0928, -0.5683, -0.5297, -0.0515, -0.6733,  0.9253,\n",
      "         0.2693,  0.2273,  0.6636,  0.2622,  0.1972,  0.2609,  0.1877, -0.3454,\n",
      "        -0.4263,  0.1398,  0.5634, -0.5691,  0.1240, -0.1289,  0.7248, -0.2610,\n",
      "        -0.2631, -0.4360,  0.0789, -0.8415,  0.5160,  1.3997, -0.7646, -3.1453,\n",
      "        -0.2920, -0.3125,  1.5129,  0.5243,  0.2146,  0.4245, -0.0884, -0.1780,\n",
      "         1.1876,  0.1058,  0.7657,  0.2191,  0.3582, -0.1164,  0.0933, -0.6248,\n",
      "        -0.2190,  0.2180,  0.7406, -0.4374,  0.1434,  0.1472, -1.1605, -0.0505,\n",
      "         0.1268, -0.0144, -0.9868, -0.0913, -1.2054, -0.1197,  0.0478, -0.5400,\n",
      "         0.5246, -0.7096, -0.3253, -0.1346, -0.4131,  0.3343, -0.0072,  0.3225,\n",
      "        -0.0442, -1.2969,  0.7622,  0.4635])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([ 0.3678,  0.3707,  0.3230, -0.4308, -0.1445, -0.1334,  0.1535, -0.2217,\n",
      "        -0.5992,  0.3777,  0.1723, -0.0807,  0.0569,  0.4515,  0.3698,  0.8605,\n",
      "         0.4426,  0.3629,  0.6153, -0.9105,  0.0376,  0.4139, -0.0827, -0.1180,\n",
      "         1.3503,  0.4124, -0.2159, -0.5544,  0.0084, -0.6314,  0.6870, -0.0588,\n",
      "         0.7506,  0.7996,  0.8289,  0.4653, -0.6595,  0.4954,  0.0275, -0.2236,\n",
      "         0.7255,  0.0690,  0.3737, -0.7849, -0.7476,  0.0609,  0.3578, -0.4475,\n",
      "        -0.2822, -0.3719, -0.5425,  0.5702, -0.3948,  0.8702, -0.0226, -0.4979,\n",
      "        -0.9112,  0.4733,  1.3760,  0.7071, -0.3753,  0.9221, -0.1518,  1.4074,\n",
      "         0.0541, -1.0608,  0.8353, -0.1927, -0.9294,  0.4286, -0.3126,  0.6241,\n",
      "         0.2037, -0.2499,  0.4961,  0.1259, -0.3700,  0.1276,  0.1655,  1.1003,\n",
      "        -0.0219,  1.6274,  0.0975, -0.7566, -0.3470, -0.5713,  0.4694,  0.4992,\n",
      "         0.1136, -0.2318,  0.2246, -0.3828, -0.1518, -0.2445,  0.6619,  0.1411,\n",
      "         0.0611,  0.1793, -0.0046, -0.4152])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([-0.2080,  0.0916, -0.2237,  0.5937,  0.4619,  0.2899, -0.5335, -0.2360,\n",
      "         0.6872,  0.4442,  0.6879, -0.2252,  0.0055, -0.2315, -0.1157,  1.0695,\n",
      "        -0.2510,  0.6929,  0.1472, -0.3486, -0.4866,  0.0035,  0.0875,  0.4450,\n",
      "         0.5186,  0.1822,  0.9791,  0.8327, -0.6620, -0.4900, -0.4109,  0.2567,\n",
      "        -0.3477, -0.0693,  0.4842,  0.5397,  0.2790,  0.9572,  0.1291, -0.0132,\n",
      "        -0.6321,  0.1722, -0.0670,  0.3760, -0.2918, -0.1191, -0.1708,  0.4151,\n",
      "        -0.0093,  0.5344,  0.2719, -0.1304, -0.3423,  0.3331, -0.5263,  0.1062,\n",
      "         0.3830, -0.7895,  0.3636, -0.1690,  0.3016, -0.3434,  0.5909,  0.2785,\n",
      "         0.4956,  0.0717,  0.6731, -0.0964, -0.4970,  0.3707, -0.8101,  0.0513,\n",
      "        -0.1641, -0.4166,  0.6077,  0.1846,  0.3672, -0.2430,  0.3417, -0.0982,\n",
      "        -0.1493, -0.3143, -0.6585,  0.5663,  0.4060,  0.8310,  0.1952,  0.1212,\n",
      "         0.0465, -0.6968, -0.8298,  0.5034, -0.3075, -0.1440,  0.7975, -1.2974,\n",
      "         0.2152, -0.3852, -0.3543,  0.3752])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "sentence = Sentence('This is Glove Embedding')\n",
    "\n",
    "stacked_embeddings.embed(sentence)\n",
    "\n",
    "\n",
    "for token in sentence:\n",
    "    print(token.embedding)\n",
    "    print(type(token.embedding))\n",
    "# storing size (length) #\n",
    "z = token.embedding.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 31962/31962 [5:47:59<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm ## tracks progress of loop ##\n",
    "\n",
    "# creating a tensor for storing sentence embeddings #\n",
    "s = torch.zeros(0,z)\n",
    "\n",
    "# iterating Sentence (tqdm tracks progress) #\n",
    "\n",
    "\n",
    "for q in tqdm(txt):\n",
    "    w = torch.zeros(0,z)\n",
    "    sentence = Sentence(q)\n",
    "    stacked_embeddings.embed(sentence)\n",
    "    for token in sentence:\n",
    "        w = torch.cat((w,token.embedding.view(-1,z)),0)\n",
    "        s = torch.cat((s, w.mean(dim = 0).view(-1, z)),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 31962/31962 [5:34:28<00:00,  1.59it/s]\n"
     ]
    }
   ],
   "source": [
    "from flair.embeddings import DocumentPoolEmbeddings\n",
    "\n",
    "\n",
    "document_embeddings = DocumentPoolEmbeddings([glove_embedding ])\n",
    "\n",
    "z = sentence.embedding.size()[0]\n",
    "\n",
    "s = torch.zeros(0,z)\n",
    "\n",
    "for tweet in tqdm(txt):\n",
    "    sentence = Sentence(tweet)\n",
    "    document_embeddings.embed(sentence)\n",
    "    s = torch.cat((s, sentence.embedding.view(-1,z)),0)\n",
    "\n",
    "torch.save(document_embeddings, 'glove_tweet_embed.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DocumentPoolEmbeddings(\n",
      "  fine_tune_mode=linear, pooling=mean\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings('glove')\n",
      "  )\n",
      "  (embedding_flex): Linear(in_features=100, out_features=100, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loaded_embeddings: DocumentPoolEmbeddings = torch.load('gloveembedding.pt')\n",
    "print(loaded_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0732,  0.1113,  0.6228, -0.3591, -0.7073,  0.4376,  0.1282,  0.1348,\n",
      "         0.3428, -0.3166])\n",
      "tensor([-0.2709,  0.0440, -0.0203, -0.1740,  0.6444,  0.7121,  0.3551,  0.4714,\n",
      "        -0.2964,  0.5443])\n",
      "tensor([ 0.1604,  0.0303, -0.2871, -0.1826, -0.4708, -0.0641, -0.0619,  0.2830,\n",
      "         0.1546, -0.4104])\n",
      "tensor([-0.2709,  0.0440, -0.0203, -0.1740,  0.6444,  0.7121,  0.3551,  0.4714,\n",
      "        -0.2964,  0.5443])\n",
      "tensor([-0.1684, -0.5383,  0.3115, -0.5322,  0.2668, -0.1364,  0.3662,  0.6838,\n",
      "         0.7773,  0.6805])\n",
      "tensor([-0.0833,  0.2392,  0.0788, -0.7250,  0.5295,  0.3875,  0.0230,  0.4968,\n",
      "        -0.4881, -0.0962])\n",
      "tensor([-0.2957,  0.3535,  0.6333,  0.1958, -0.0303,  0.5424, -0.2109,  0.3289,\n",
      "        -0.4889,  0.1838])\n"
     ]
    }
   ],
   "source": [
    "sentence = Sentence('when a saw a car run over')\n",
    "loaded_embeddings.embed(sentence)\n",
    "\n",
    "# print embeddings\n",
    "for token in sentence:\n",
    "    print(token.embedding[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-18 20:06:14,160 loading file gloveembedding.pt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'DocumentPoolEmbeddings' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-63fe355dfb72>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextClassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'gloveembedding.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# create example sentence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\flair\\nn.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(cls, model)\u001b[0m\n\u001b[0;32m    101\u001b[0m             \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflair\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_model_with_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\flair\\models\\text_classification_model.py\u001b[0m in \u001b[0;36m_init_model_with_state_dict\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         model = TextClassifier(\n\u001b[1;32m---> 93\u001b[1;33m             \u001b[0mdocument_embeddings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"document_embeddings\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m             \u001b[0mlabel_dictionary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"label_dictionary\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[0mmulti_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"multi_label\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'DocumentPoolEmbeddings' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "\n",
    "classifier = TextClassifier.load('gloveembedding.pt')\n",
    "\n",
    "# create example sentence\n",
    "sentence = Sentence('when a saw a car run over')\n",
    "\n",
    "# predict tags and print\n",
    "classifier.predict(sentence)\n",
    "\n",
    "print(sentence.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5001, 100)\n",
      "(5000, 100)\n"
     ]
    }
   ],
   "source": [
    "## tensor to numpy array ##\n",
    "import numpy as np\n",
    "\n",
    "##df = pd.read_csv('C:/Dataset.csv')\n",
    "#data['split'] = np.random.randn(data.shape[0], 1)\n",
    "\n",
    "#msk = np.random.rand(len(data)) <= 0.5\n",
    "\n",
    "#train = data[msk]\n",
    "#test = data[~msk]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = s.detach().numpy()   \n",
    "\n",
    "## Test set ##\n",
    "test = X[5001:,:]\n",
    "train = X[:5001,:]\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "# extracting labels of the training set #\n",
    "target = data['label'].values\n",
    "#target = data['label'][data['label'].isnull()==False].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_eval(preds, dtrain):\n",
    "    labels = dtrain.get_label().astype(np.int)\n",
    "    preds = (preds >= 0.3).astype(np.int)\n",
    "    return [('f1_score', f1_score(labels, preds))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [5001, 10001]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-6b579f8cacbc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m x_train, x_valid, y_train, y_valid = train_test_split(train, target,  \n\u001b[0;32m      7\u001b[0m                                                       \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                                                           test_size=0.3)\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m### XGBoost compatible data ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m   2013\u001b[0m         \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2014\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2015\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2016\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2017\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 173\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [5001, 10001]"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "### Splitting training set ###\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(train, target,  \n",
    "                                                      random_state=42, \n",
    "                                                          test_size=0.3)\n",
    "\n",
    "### XGBoost compatible data ###\n",
    "dtrain = xgb.DMatrix(x_train,y_train)         \n",
    "dvalid = xgb.DMatrix(x_valid, label = y_valid)\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "\n",
    "\n",
    "### defining parameters ###\n",
    "params = {\n",
    "          'colsample': 0.9,\n",
    "          'colsample_bytree': 0.5,\n",
    "          'eta': 0.1,\n",
    "          'max_depth': 8,\n",
    "          'min_child_weight': 6,\n",
    "          'objective': 'multi:softmax',\n",
    "          'num_class':6,\n",
    "          'subsample': 0.9\n",
    "          }\n",
    "\n",
    "### Training the model ###\n",
    "xgb_model = xgb.train(\n",
    "                      params,\n",
    "                      dtrain,\n",
    "                      feval= custom_eval,\n",
    "                      num_boost_round= 1000,\n",
    "                      maximize=True,\n",
    "                    #  evals=[(dvalid, \"Validation\")],\n",
    "                      evals= watchlist,\n",
    "                      early_stopping_rounds=30\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reformatting test set for XGB ###\n",
    "dtest = xgb.DMatrix(test)\n",
    "\n",
    "### Predicting ###\n",
    "predict = xgb_model.predict(dtest) # predicting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
