{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import flair\n",
    "import bert_embedding\n",
    "from flair.data import Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>i feel so enraged but helpless at the same time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>i just dont know why i am feeling so determine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>i feel just terrible a   dirigonzo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>i feel that i missed a bunch of names this mor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>i still count that as one of the most well wri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0    i feel so enraged but helpless at the same time\n",
       "1   2      2  i just dont know why i am feeling so determine...\n",
       "2   3      3                 i feel just terrible a   dirigonzo\n",
       "3   4      3  i feel that i missed a bunch of names this mor...\n",
       "4   5      4  i still count that as one of the most well wri..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "import pandas as pd\n",
    "data = pd.read_csv('Testing_Emotions_corrected_indexed.csv') \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i feel so enraged but helpless at the same time', 'i just dont know why i am feeling so determined but i am', 'i feel just terrible a   dirigonzo', 'i feel that i missed a bunch of names this morning the group looked so large', 'i still count that as one of the most well written books i ve ever read but it feels weird to enjoy this person s work', 'i feel honoured to be ranked among them', 'i was feeling determined i figured i could overcome my 1 of heights for the sake of another tick on the bucket list', 'i like it there because well i guess i feel welcomed', 'i feel i should say talented yet again', 'i feel like im less afraid of doing a natural type look now but at the same time i dont think its my favourite thing to try']\n"
     ]
    }
   ],
   "source": [
    "text = data['tweet']\n",
    "txt = text.tolist()\n",
    "print(txt[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings\n",
    "from flair.embeddings import CharacterEmbeddings\n",
    "from flair.embeddings import StackedEmbeddings\n",
    "from flair.embeddings import FlairEmbeddings\n",
    "from flair.embeddings import BertEmbeddings\n",
    "from flair.embeddings import ELMoEmbeddings\n",
    "\n",
    "\n",
    "### Initialising embeddings (un-comment to use others) ###\n",
    "\n",
    "glove_embedding = WordEmbeddings('glove')\n",
    "character_embeddings = CharacterEmbeddings()\n",
    "flair_forward  = FlairEmbeddings('news-forward-fast')\n",
    "flair_backward = FlairEmbeddings('news-backward-fast')\n",
    "bert_embedding = BertEmbeddings()\n",
    "\n",
    "stacked_embeddings = StackedEmbeddings( embeddings = [ \n",
    "                                                      bert_embedding,\n",
    "                                                      #elmo_embedding\n",
    "                                                   ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6327, -0.4104,  0.1828,  ..., -0.5955, -0.1193,  0.6265])\n",
      "tensor([-0.3797, -0.4740,  0.5282,  ..., -0.4815, -0.0980,  1.0802])\n",
      "tensor([ 0.4525,  0.0918,  0.4873,  ...,  0.6933, -0.1054, -0.0516])\n",
      "tensor([ 0.1616,  0.0039, -0.3333,  ...,  0.0916,  0.0540,  0.1815])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "sentence = Sentence('This is BERT Embedding')\n",
    "\n",
    "stacked_embeddings.embed(sentence)\n",
    "\n",
    "\n",
    "for token in sentence:\n",
    "  print(token.embedding)\n",
    "# data type and size of embedding #\n",
    "print(type(token.embedding))\n",
    "# storing size (length) #\n",
    "z = token.embedding.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|█████████████████████████████▌                                          | 4113/10001 [9:17:37<26:02:24, 15.92s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm ## tracks progress of loop ##\n",
    "\n",
    "# creating a tensor for storing sentence embeddings #\n",
    "s = torch.zeros(0,z)\n",
    "\n",
    "# iterating Sentence (tqdm tracks progress) #\n",
    "\n",
    "\n",
    "for q in tqdm(txt):\n",
    "    w = torch.zeros(0,z)\n",
    "    sentence = Sentence(q)\n",
    "    stacked_embeddings.embed(sentence)\n",
    "    for token in sentence:\n",
    "        w = torch.cat((w,token.embedding.view(-1,z)),0)\n",
    "        s = torch.cat((s, w.mean(dim = 0).view(-1, z)),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import DocumentPoolEmbeddings\n",
    "\n",
    "document_embeddings = DocumentPoolEmbeddings([bert_embedding,\n",
    "                                                      ])\n",
    "z = sentence.embedding.size()[1]\n",
    "\n",
    "s = torch.zeros(0,z)\n",
    "\n",
    "for tweet in tqdm(txt):\n",
    "    sentence = Sentence(tweet)\n",
    "    document_embeddings.embed(sentence)\n",
    "    s = torch.cat((s, sentence.embedding.view(-1,z)),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tensor to numpy array ##\n",
    "X = s.numpy()   \n",
    "\n",
    "## Test set ##\n",
    "test = X[3962:,:]\n",
    "train = X[:3962,:]\n",
    "\n",
    "# extracting labels of the training set #\n",
    "target = data['label'][data['label'].isnull()==False].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_eval(preds, dtrain):\n",
    "    labels = dtrain.get_label().astype(np.int)\n",
    "    preds = (preds >= 0.3).astype(np.int)\n",
    "    return [('f1_score', f1_score(labels, preds))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "### Splitting training set ###\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(train, target,  \n",
    "                                                      random_state=42, \n",
    "                                                          test_size=0.3)\n",
    "\n",
    "### XGBoost compatible data ###\n",
    "dtrain = xgb.DMatrix(x_train,y_train)         \n",
    "dvalid = xgb.DMatrix(x_valid, label = y_valid)\n",
    "\n",
    "### defining parameters ###\n",
    "params = {\n",
    "          'colsample': 0.9,\n",
    "          'colsample_bytree': 0.5,\n",
    "          'eta': 0.1,\n",
    "          'max_depth': 8,\n",
    "          'min_child_weight': 6,\n",
    "          'objective': 'binary:logistic',\n",
    "          'subsample': 0.9\n",
    "          }\n",
    "\n",
    "### Training the model ###\n",
    "xgb_model = xgb.train(\n",
    "                      params,\n",
    "                      dtrain,\n",
    "                      feval= custom_eval,\n",
    "                      num_boost_round= 1000,\n",
    "                      maximize=True,\n",
    "                      evals=[(dvalid, \"Validation\")],\n",
    "                      early_stopping_rounds=30\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reformatting test set for XGB ###\n",
    "dtest = xgb.DMatrix(test)\n",
    "\n",
    "### Predicting ###\n",
    "predict = xgb_model.predict(dtest) # predicting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
